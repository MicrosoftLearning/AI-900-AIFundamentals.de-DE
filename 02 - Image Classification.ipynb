{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bildklassifizierung\r\n",
        "\r\n",
        "Der Cognitive Service für *maschinelles Sehen* stellt nützliche vorab erstellte Modelle für die Arbeit mit Bildern bereit. Trotzdem müssen Sie oft eigene Modelle für das maschinelle Sehen trainieren. Angenommen, das Einzelhandelsunternehmen Northwind Traders möchte ein automatisiertes Kassensystem erstellen, das die vom Kunden gekauften Waren anhand von Kamerabildern beim Bezahlen erkennt. Dazu müssen Sie ein Klassifizierungsmodell trainieren, das die Bilder klassifiziert und die gekauften Waren identifiziert.\r\n",
        "\r\n",
        "![Ein Roboter mit einem Klemmbrett, der Bilder von einem Apfel, einer Banane und einer Orange klassifiziert](./images/image-classification.jpg)\r\n",
        "\r\n",
        "In Azure können Sie den Cognitive Service ***Custom Vision*** verwenden, um ein Bildklassifizierungsmodell mit vorhandenen Bildern zu trainieren. Zu einer Bildklassifizierungslösung gehören zwei Elemente. Zunächst trainieren Sie ein Modell, das unterschiedliche Klassen anhand von vorhandenen Bildern erkennt. Nachdem das Modell trainiert wurde, veröffentlichen Sie es als Dienst, der von Anwendungen genutzt werden kann.\r\n",
        "\r\n",
        "## Erstellen einer Custom Vision-Ressource\r\n",
        "\r\n",
        "Um den Custom Vision-Dienst nutzen zu können, benötigen Sie eine Azure-Ressource, mit der Sie ein Modell *trainieren* können, und eine Ressource, mit der Sie den Dienst *veröffentlichen* und für Anwendungen bereitstellen können. Für diese Aufgaben können Sie entweder eine allgemeine **Cognitive Services**-Ressource oder eine spezifische **Custom Vision**-Ressource verwenden. Sie können entweder dieselbe Cognitive Services-Ressource für beide Aufgaben verwenden, oder Sie können getrennte Ressourcen (in derselben Region) verwenden, um die Kosten separat zu verwalten.\r\n",
        "\r\n",
        "Gehen Sie wie folgt vor, um eine neue **Custom Vision**-Ressource zu erstellen.\r\n",
        "\r\n",
        "1. Öffnen Sie das Azure-Portal unter [https://portal.azure.com](https://portal.azure.com) in einer neuen Browserregisterkarte, und melden Sie sich mit dem Microsoft-Konto an, das Ihrem Azure-Abonnement zugeordnet ist.\r\n",
        "2. Wählen Sie die Schaltfläche **&#65291;Ressource erstellen** aus, suchen Sie nach *custom vision*, und erstellen Sie eine **Custom Vision**-Ressource mit den folgenden Einstellungen:\r\n",
        "    - **Erstellungsoptionen**: Beide\r\n",
        "    - **Abonnement**: *Ihr Azure-Abonnement*\r\n",
        "    - **Ressourcengruppe**: *Wählen Sie eine Ressourcengruppe aus, oder erstellen Sie eine Ressourcengruppe mit einem eindeutigen Namen.*\r\n",
        "    - **Name**: *Geben Sie einen eindeutigen Namen ein.*\r\n",
        "    - **Speicherort für das Training**: *Wählen Sie eine verfügbare Region aus.*\r\n",
        "    - **Tarif für Training**: F0\r\n",
        "    - **Speicherort für die Vorhersage**: *Dieselbe Region wie die Trainingsressource*\r\n",
        "    - **Tarif für Vorhersage**: F0\r\n",
        "\r\n",
        "    > **Hinweis**: Falls Ihr Abonnement bereits einen F0 Custom Vision-Dienst enthält, wählen Sie hier **S0** aus.\r\n",
        "\r\n",
        "3. Warten Sie, bis die Ressourcen erstellt wurden, und beachten Sie, dass zwei Custom Vision-Ressourcen bereitgestellt wurden, je eine für Training und Vorhersage. Sie können diese Ressourcen anzeigen, indem Sie zur Ressourcengruppe navigieren, in der Sie sie erstellt haben.\r\n",
        "\r\n",
        "## Erstellen eines Custom Vision-Projekts\r\n",
        "\r\n",
        "Um ein Objekterkennungsmodell zu trainieren, müssen Sie ein Custom Vision-Projekt mit Ihrer Trainingsressource erstellen. Dazu verwenden Sie das Custom Vision-Portal.\r\n",
        "\r\n",
        "1. Laden Sie die Trainingsbilder unter „https://aka.ms/fruit-images“ herunter, und extrahieren Sie sie. **Hinweis:** Falls Sie nicht auf die Training-Images zugreifen können, navigieren Sie als temporäre Problemumgehung zu https://www.github.com, then go to https://aka.ms/fruit-images.  \r\n",
        "2. Öffnen Sie das Custom Vision-Portal unter [https://customvision.ai](https://customvision.ai) in einer neuen Browserregisterkarte. Falls Sie dazu aufgefordert werden, melden Sie sich mit dem Microsoft-Konto an, das Ihrem Azure-Abonnement zugeordnet ist, und stimmen Sie den Nutzungsbedingungen zu.\r\n",
        "3. Erstellen Sie im Custom Vision-Portal ein neues Projekt mit den folgenden Einstellungen:\r\n",
        "    - **Name**: Grocery Checkout\r\n",
        "    - **Beschreibung**: Bildklassifizierung für Lebensmittel\r\n",
        "    - **Ressource**: *Die zuvor erstellte Custom Vision-Ressource*\r\n",
        "    - **Projekttypen**: Klassifizierung\r\n",
        "    - **Klassifizierungstypen**: Multiklasse (einzelnes Tag pro Bild)\r\n",
        "    - **Domänen**: Lebensmittel\r\n",
        "4. Klicken Sie auf **\\[+\\] Bilder hinzufügen**, und wählen Sie alle Dateien in dem Ordner **apple** aus, den Sie zuvor extrahiert haben. Laden Sie anschließend die Bilddateien mit dem Tag *Apfel* hoch:\r\n",
        "\r\n",
        "![Apfel-Upload mit Tag „Apfel“](./images/upload_apples.jpg)\r\n",
        "   \r\n",
        "5. Wiederholen Sie den vorherigen Schritt, um die Bilder im Ordner **banana** mit dem Tag *Banane* und die Bilder im Ordner **orange** mit dem Tag *Orange* hochzuladen.\r\n",
        "6. Sehen Sie sich die Bilder an, die Sie in Ihrem Custom Vision-Projekt hochgeladen haben. Sie sollten 15 Bilder pro Klasse haben, wie hier gezeigt:\r\n",
        "\r\n",
        "![Bilder von Obst mit Tags – 15 Äpfel, 15 Bananen und 15 Orangen](./images/fruit.jpg)\r\n",
        "    \r\n",
        "7. Klicken Sie im Custom Vision-Projekt über den Bildern auf **Trainieren**, um ein Klassifizierungsmodell mit den markierten Bildern zu trainieren. Wählen Sie die Option **Schnelltraining** aus, und warten Sie, bis die Trainingsiteration abgeschlossen wurde (dieser Vorgang kann etwa eine Minute dauern).\r\n",
        "8. Warten Sie, bis die Modelliteration trainiert wurde, und überprüfen Sie die Leistungsmetriken *Genauigkeit*, *Abruf* und *AP*. Diese Metriken messen die Vorhersagegenauigkeit des Klassifizierungsmodells und sollten jeweils den Wert „Hoch“ haben.\r\n",
        "\r\n",
        "## Testen des Modells\r\n",
        "\r\n",
        "Bevor Sie diese Iteration des Modells für Ihre Anwendungen veröffentlichen, sollten Sie es testen.\r\n",
        "\r\n",
        "1. Klicken Sie über den Leistungsmetriken auf **Schnelltest**.\r\n",
        "2. Geben Sie `https://aka.ms/apple-image` in das Feld **Bild-URL** ein, und klicken Sie auf &#10132;\r\n",
        "3. Sehen Sie sich die von Ihrem Modell zurückgegebenen Vorhersagen an. *Apfel* sollte den höchsten Wahrscheinlichkeitswert haben, wie hier gezeigt:\r\n",
        "\r\n",
        "![Ein Bild mit der Klassenvorhersage „Apfel“](./images/test-apple.jpg)\r\n",
        "\r\n",
        "4. Schließen Sie das Fenster **Schelltest**.\r\n",
        "\r\n",
        "## Veröffentlichen und Verwenden des Bildklassifizierungsmodells\r\n",
        "\r\n",
        "Sie können Ihr trainiertes Modell jetzt veröffentlichen und aus einer Clientanwendung heraus verwenden.\r\n",
        "\r\n",
        "9. Klicken Sie auf **&#128504; Veröffentlichen**, um das trainierte Modell mit den folgenden Einstellungen zu veröffentlichen:\r\n",
        "    - **Modellname**: groceries\r\n",
        "    - **Vorhersageressource**: *Die zuvor erstellte Vorhersageressource*.\r\n",
        "\r\n",
        "### (!) Überprüfung \r\n",
        "Haben Sie den gleichen Modellnamen (**groceries**) verwendet?   \r\n",
        "\r\n",
        "10. Klicken Sie nach dem Veröffentlichen auf das Symbol *Einstellungen* (&#9881;) oben rechts auf der Seite **Leistung**, um die Projekteinstellungen zu öffnen. Kopieren Sie anschließend unter **Allgemein** (linke Seite) die **Projekt-ID**. Scrollen Sie nach unten, und fügen Sie sie in die Codezelle unter Schritt 13 anstelle von **YOUR_PROJECT_ID** ein.\r\n",
        "\r\n",
        "![Projekt-ID in den Projekteinstellungen](./images/cv_project_settings.jpg)\r\n",
        "\r\n",
        "> _**Hinweis**: Falls Sie am Anfang dieses Labs eine **Cognitive Services**-Ressource verwendet haben, anstatt eine **Custom Vision** zu erstellen, können Sie den Schlüssel und den Endpunkt auf der rechten Seite der Projekteinstellungen kopieren, in die Codezelle unten einfügen und sie anschließend ausführen, um das Ergebnis anzuzeigen. Führen Sie andernfalls die folgenden Schritte aus, um den Schlüssel und den Endpunkt für Ihre Custom Vision-Vorhersageressource abzurufen._\r\n",
        "\r\n",
        "11. Klicken Sie links oben auf der Seite **Projekteinstellungen** auf das Symbol für den *Projektkatalog* (&#128065;), um zur Startseite des Custom Vision-Portals zu gelangen, auf der Ihr Projekt jetzt aufgelistet wird.\r\n",
        "\r\n",
        "12. Klicken Sie auf der Startseite des Custom Vision-Portals oben rechts auf das Symbol *Einstellungen* (&#9881;), um die Einstellungen für Ihren Custom Vision-Dienst anzuzeigen. Erweitern Sie anschließend unter **Ressourcen** Ihre **Vorhersageressource** (<u>nicht</u> die Trainingsressource), und kopieren Sie die Werte unter **Schlüssel** und **Endpunkt** in die Codezelle unter Schritt 13. Ersetzen Sie dabei **YOUR_KEY** und **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) Überprüfung \r\n",
        "Falls Sie eine **Custom Vision**-Ressource verwenden: Haben Sie die **Vorhersageressource** verwendet (<u>nicht</u> die Trainingsressource)?\r\n",
        "\r\n",
        "![Schlüssel und Endpunkt der Vorhersageressource in den Custom Vision-Einstellungen](./images/cv_settings.jpg)\r\n",
        "\r\n",
        "13. Führen Sie die folgende Codezelle aus, indem Sie links neben der Zelle auf die Schaltfläche **Zelle ausführen** (&#9655;) klicken, um Ihre Werte für Projekt-ID, Schlüssel und Endpunkt als Variablenwerte festzulegen."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\r\n",
        "cv_key = 'YOUR_KEY'\r\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\r\n",
        "\r\n",
        "model_name = 'groceries' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\r\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anschließend können Sie Ihren Schlüssel und Endpunkt in einem Custom Vision-Client verwenden, um sich mit Ihrem Custom Vision-Klassifizierungsmodell zu verbinden.\r\n",
        "\r\n",
        "Führen Sie die folgende Codezelle aus, um eine Auswahl an Testbildern mit Ihrem veröffentlichten Modell zu klassifizieren.\r\n",
        "\r\n",
        "> **Hinweis**: Sorgen Sie sich nicht zu sehr um die Codedetails. Der Code verwendet das Computer Vision-SDK für Python, um Klassenvorhersagen für die einzelnen Bilder im Ordner „/data/image-classification/test-fruit“ zu erhalten."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
        "from msrest.authentication import ApiKeyCredentials\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# Get the test images from the data/vision/test folder\r\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\r\n",
        "test_images = os.listdir(test_folder)\r\n",
        "\r\n",
        "# Create an instance of the prediction service\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\r\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\r\n",
        "\r\n",
        "# Create a figure to display the results\r\n",
        "fig = plt.figure(figsize=(16, 8))\r\n",
        "\r\n",
        "# Get the images and show the predicted classes for each one\r\n",
        "print('Classifying images in {} ...'.format(test_folder))\r\n",
        "for i in range(len(test_images)):\r\n",
        "    # Open the image, and use the custom vision model to classify it\r\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\r\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\r\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\r\n",
        "    prediction = classification.predictions[0].tag_name\r\n",
        "    # Display the image with its predicted class\r\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\r\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\r\n",
        "    a.axis('off')\r\n",
        "    imgplot = plt.imshow(img)\r\n",
        "    a.set_title(prediction)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ihr Bildklassifizierungsmodell hat nun hoffentlich die Lebensmittel in den Bildern korrekt identifiziert.\r\n",
        "\r\n",
        "## Weitere Informationen\r\n",
        "\r\n",
        "Der Custom Vision-Dienst enthält noch weitere Funktionen, auf die wir in diesem Lab nicht eingegangen sind. Mit dem Custom Vision-Dienst können Sie beispielsweise *Objekterkennungsmodelle* erstellen, die nicht nur Objekte in Bilder klassifizieren, sondern auch *Begrenzungsrahmen* für die Position des Objekts innerhalb des Bilds identifizieren.\r\n",
        "\r\n",
        "Weitere Informationen zum Cognitive Service „Custom Vision“ finden Sie in der [Custom Vision-Dokumentation](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}