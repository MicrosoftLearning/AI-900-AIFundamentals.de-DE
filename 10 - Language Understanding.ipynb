{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Understanding\r\n",
        "\r\n",
        "Wir erwarten immer häufiger, dass Computer KI einsetzen können, um gesprochene oder eingegebene Befehle in natürlicher Sprache zu verstehen. Angenommen, Sie möchten ein Gebäudeautomatisierungssystem entwickeln, um die Geräte in Ihrem Zuhause mit Sprachbefehlen wie etwa „Licht einschalten“ oder „Ventilator einschalten“ steuern zu können, die von einem Gerät mit KI-Unterstützung verstanden und ausgeführt werden.\r\n",
        "\r\n",
        "![Ein Roboter, der zuhört](./images/language_understanding.jpg)\r\n",
        "\r\n",
        "## Erstellen von Erstellungs- und Vorhersageressourcen\r\n",
        "\r\n",
        "Zu den Cognitive Services von Microsoft gehört auch der Dienst „Language Understanding“, mit dem Sie *Absichten* definieren können, die basierend auf *Äußerungen* auf *Entitäten* angewendet werden. \r\n",
        "\r\n",
        "Um den Dienst „Language Understanding“ verwenden zu können, benötigen Sie zwei Arten von Ressourcen:\r\n",
        "\r\n",
        "- Eine *Erstellungsressource*, mit der Sie das Sprachmodell definieren, trainieren und testen. Diese Ressource muss als **Language Understanding – Erstellung**-Ressource in Ihrem Azure-Abonnement erstellt werden.\r\n",
        "- Eine *Vorhersageressource*, mit der Sie das Modell veröffentlichen und die Anforderungen von Clientanwendungen verarbeiten, die das Modell aufrufen. Diese Ressource muss entweder als **Language Understanding**- oder als **Cognitive Services**-Ressource in Ihrem Azure-Abonnement erstellt werden.\r\n",
        "\r\n",
        "Sie können entweder eine **Language Understanding**- oder eine **Cognitive Services**-Ressource verwenden, um eine Language Understanding-App zu *veröffentlichen*, aber Sie müssen eine separate **Language Understanding**-Ressource für die *Erstellung* der App erstellen.\r\n",
        "\r\n",
        "> **Wichtig**: Erstellungsressourcen müssen in einer von drei *Regionen* erstellt werden (Europa, Australien oder USA). Modelle, die in europäischen oder australischen Erstellungsressourcen erstellt wurden, können nur in Vorhersageressourcen in Europa bzw. in Australien bereitgestellt werden. Modelle, die in US-Erstellungsressourcen erstellt wurden, können in Vorhersageressourcen in beliebigen Azure-Standorten bereitgestellt werden, mit Ausnahme von Europa und Australien. Weitere Details zu kompatiblen Erstellungs- und Veröffentlichungsstandorten finden Sie in der [Dokumentation zu Erstellungs- und Veröffentlichungsregionen](https://docs.microsoft.com/azure/cognitive-services/luis/luis-reference-regions).\r\n",
        "\r\n",
        "1. Öffnen Sie das Azure-Portal unter [https://portal.azure.com](https://portal.azure.com) in einer neuen Browserregisterkarte, und melden Sie sich mit Ihrem Microsoft-Konto an.\r\n",
        "2. Klicken Sie auf **+ Ressource erstellen**, und suchen Sie nach *Language Understanding*.\r\n",
        "3. Wählen Sie in der Liste der Dienste **Language Understanding** aus.\r\n",
        "4. Klicken Sie auf dem Blatt **Language Understanding** auf **Erstellen**.\r\n",
        "5. Geben Sie die folgenden Informationen im Blatt **Erstellen** ein, und klicken Sie dann auf **Erstellen**.\r\n",
        "   - **Erstellungsoption**: Beide\r\n",
        "   - **Name**: *Ein eindeutiger Name für Ihren Dienst*\r\n",
        "   - **Abonnement**: *Wählen Sie Ihr Azure-Abonnement aus.*\r\n",
        "   - **Ressourcengruppe**: *Wählen Sie eine vorhandene Ressourcengruppe aus, oder erstellen Sie eine neue.*\r\n",
        "   - **Speicherort für Dokumenterstellung**: *Wählen Sie Ihren bevorzugten Speicherort aus.*\r\n",
        "   - **Tarif für die Erstellung**: F0\r\n",
        "   - **Speicherort für die Vorhersage**: *Wählen Sie einen Speicherort in der Region aus, die Sie unter „Speicherort für Dokumenterstellung“ angegeben haben.*\r\n",
        "   - **Tarif für Vorhersage**: F0\r\n",
        "   \r\n",
        "6. Warten Sie, bis die Ressourcen erstellt wurden, und beachten Sie, dass zwei Language Understanding-Ressourcen bereitgestellt wurden, je eine für Erstellung und Vorhersage. Sie können diese Ressourcen anzeigen, indem Sie zur Ressourcengruppe navigieren, in der Sie sie erstellt haben.\r\n",
        "\r\n",
        "### Erstellen einer Language Understanding-App\r\n",
        "\r\n",
        "Um natürliches Sprachverständnis mit dem Dienst „Language Understanding“ zu implementieren, erstellen Sie zunächst eine App und fügen anschließend Entitäten, Absichten und Äußerungen hinzu, um die Befehle zu definieren, die die App verstehen soll.\r\n",
        "\r\n",
        "1. Öffnen Sie das Language Understanding-Portal für die Region, in der Sie Ihre Erstellungsressource erstellt haben, in einer neuen Browserregisterkarte:\r\n",
        "    - USA: [https://www.luis.ai](https://www.luis.ai)\r\n",
        "    - Europa: [https://eu.luis.ai](https://eu.luis.ai)\r\n",
        "    - Australien: [https://au.luis.ai](https://au.luis.ai)\r\n",
        "\r\n",
        "2. Melden Sie sich mit Ihrem Microsoft-Konto an, das mit Ihrem Azure-Abonnement verknüpft ist. Wenn Sie sich zum ersten Mal beim Language Understanding-Portal anmelden, müssen Sie der App unter Umständen bestimmte Berechtigungen für den Zugriff auf Ihre Kontodetails erteilen. Schließen Sie anschließend die *Willkommens*-Schritte ab, indem Sie die vorhandene Language Understanding-Erstellungsressource auswählen, die Sie zuvor in Ihrem Azure-Abonnement erstellt haben. \r\n",
        "\r\n",
        "3. Öffnen Sie die Seite **Unterhaltungs-Apps**, und wählen Sie Ihr Abonnement und Ihre Language Understanding-Erstellungsressource aus. Erstellen Sie anschließend eine neue Konversations-App mit den folgenden Einstellungen:\r\n",
        "   - **Name**: Home Automation\r\n",
        "   - **Kultur**: Deutsch (*Lassen Sie das Feld leer, falls diese Option nicht verfügbar ist.*)\r\n",
        "   - **Beschreibung**: Einfache Gebäudeautomatisierung\r\n",
        "   - **Vorhersageressource**: *Ihre Language Understanding-Vorhersageressource*\r\n",
        "\r\n",
        "4. Falls ein Bereich mit Tipps zum Erstellen einer effektiven Language Understanding-App angezeigt wird, schließen Sie ihn.\r\n",
        "\r\n",
        "### Erstellen einer Entität\r\n",
        "\r\n",
        "Eine *Entität* ist etwas, das Ihr Sprachmodell identifizieren und mit dem es interagieren kann. In diesem Fall verwenden Sie Ihre Language Understanding-App, um verschiedene *Geräte* im Büro zu steuern, zum Beispiel Lampen oder Ventilatoren. Daher erstellen Sie eine Entität *Gerät* mit einer Liste der Gerätetypen, mit denen die App interagieren soll. Für jeden Gerätetyp erstellen Sie eine untergeordnete Liste, die den Namen des Geräts (z. B. *Licht*) sowie sämtliche Synonyme enthält, die Sie für diesen Gerätetyp verwenden können (z. B. *Lampe*).\r\n",
        "\r\n",
        "1. Klicken Sie auf der Language Understanding-Seite für Ihre App im linken Bereich auf **Entitäten**. Klicken Sie dann auf **Erstellen**, erstellen Sie eine neue Entität mit dem Namen **Gerät**, wählen Sie den Typ **Liste** aus, und klicken Sie auf **Erstellen**.\r\n",
        "2. Geben Sie auf der Seite **Listenelemente** unter **Normalisierte Werte** den Wert **Licht** ein, und drücken Sie die Eingabetaste.\r\n",
        "3. Nachdem der Wert **Licht** hinzugefügt wurde, geben Sie unter **Synonyme** den Wert **Lampe** ein und drücken die Eingabetaste.\r\n",
        "4. Fügen Sie ein zweites Listenelement mit dem Namen **Ventilator** und dem Synonym **Lüftung** hinzu.\r\n",
        "\r\n",
        "> **Hinweis**: Verwenden Sie für dieses Lab die genaue Groß- und Kleinschreibung wie in den Anweisungen _(Beispiel: licht, und **nicht** Licht)_, und fügen Sie keine zusätzlichen Leerzeichen ein. \r\n",
        "\r\n",
        "### Erstellen von Absichten\r\n",
        "\r\n",
        "Eine *Absicht* ist eine Aktion, die Sie für eine oder mehrere Entitäten ausführen möchten, wenn Sie z. B. eine Lampe einschalten oder einen Ventilator ausschalten. In diesem Fall definieren Sie zwei Absichten: eine, um ein Gerät einzuschalten und eine, um es auszuschalten. Für jede Absicht legen Sie Beispiele für *Äußerungen* fest, um anzugeben, mit welchen Befehlen die Absicht ausgedrückt wird.\r\n",
        "\r\n",
        "> **Hinweis**: Verwenden Sie für dieses Lab die genaue Groß- und Kleinschreibung wie in den Anweisungen _(Beispiel: „licht einschalten“, und **nicht** „Licht einschalten .)_, und fügen Sie keine zusätzlichen Leerzeichen ein. \r\n",
        "\r\n",
        "1. Klicken Sie im Menü auf der linken Seite auf **Absichten**. Klicken Sie dann auf **Erstellen**, fügen Sie eine Absicht mit dem Namen **einschalten** hinzu, und klicken Sie auf **Fertig**.\r\n",
        "2. Geben Sie unter der Überschrift **Beispiele** und der Unterüberschrift **Beispieleingabe** die Äußerung ***licht einschalten*** ein, und drücken Sie die **Eingabetaste**, um diese Äußerung zur Liste hinzuzufügen.\r\n",
        "3. Klicken Sie in der Äußerung *Licht einschalten* auf das Wort „licht“, und weisen Sie dem Wert **licht** der Entität **Gerät** zu.\r\n",
        "\r\n",
        "![So weisen Sie das Wort „licht“ zum Entitätswert zu.](./images/assign_entity.jpg)\r\n",
        "\r\n",
        "4. Fügen Sie eine zweite Äußerung zur Absicht **einschalten** mit dem Ausdruck ***ventilator einschalten*** hinzu. Weisen Sie anschließend das Wort „ventilator“ zum Wert **ventilator** der Entität **Gerät** zu.\r\n",
        "5. Klicken Sie im Menü auf der linken Seite auf **Absichten**, und klicken Sie auf **Erstellen**, um eine zweite Absicht mit dem Namen **ausschalten** hinzuzufügen.\r\n",
        "6. Fügen Sie auf der Seite **Äußerungen** für die Absicht **ausschalten** die Äußerung ***licht ausschalten*** hinzu, und weisen Sie das Wort „licht“ dem Wert **licht** der Entität **Gerät** zu.\r\n",
        "7. Fügen Sie eine zweite Äußerung zur Absicht **ausschalten** mit dem Ausdruck ***ventilator ausschalten*** hinzu. Verknüpfen Sie anschließend das Wort „ventilator“ mit dem Wert **ventilator** der Entität **Gerät**.\r\n",
        "\r\n",
        "### Trainieren und Testen des Sprachmodells\r\n",
        "\r\n",
        "Jetzt können Sie die in Form von Entitäten, Absichten und Äußerungen angegebenen Daten verwenden, um das Sprachmodell für Ihre App zu trainieren.\r\n",
        "\r\n",
        "1. Klicken Sie oben auf der Language Understanding-Seite für Ihre App auf **Trainieren**, um das Sprachmodell zu trainieren.\r\n",
        "2. Trainieren Sie das Modell, klicken Sie anschließend auf **Testen**, und verwenden Sie den Bereich „Testen“, um die vorhergesagten Absichten für die folgenden Ausdrücke anzuzeigen:\r\n",
        "    * *licht anschalten*\r\n",
        "    * *ventilator ausschalten*\r\n",
        "    * *lampe ausschalten*\r\n",
        "    * *lüftung einschalten*\r\n",
        "3. Schließen Sie den Bereich „Testen“.\r\n",
        "    \r\n",
        "### Veröffentlichen des Modells und Konfigurieren der Endpunkte\r\n",
        "\r\n",
        "Um Ihr trainiertes Modell in einer Clientanwendung verwenden zu können, müssen Sie es als Endpunkt veröffentlichen, an den die Clientanwendungen neue Äußerungen senden können und von dem sie vorhergesagte Absichten und Entitäten erhalten.\r\n",
        "\r\n",
        "1. Klicken Sie oben auf der Language Understanding-Seite für Ihre App auf **Veröffentlichen**. Wählen Sie anschließend **Produktionsslot** aus, und klicken Sie auf **Fertig**.\r\n",
        "\r\n",
        "2. Nachdem das Modell veröffentlicht wurde, klicken Sie oben auf der Language Understanding-Seite für Ihre App auf **Verwalten**. Notieren Sie sich anschließend auf der Registerkarte **Einstellungen** die **App-ID** für Ihre App. Kopieren Sie diesen Wert, und fügen Sie ihn unten im Code anstelle von **YOUR_LU_APP_ID** ein.\r\n",
        "\r\n",
        "3. Notieren Sie sich auf der Registerkarte **Azure-Ressourcen** den **Primärschlüssel** und die **Endpunkt-URL** für Ihre Vorhersageressource. Kopieren Sie diese Werte, und fügen Sie sie unten im Code anstelle von **YOUR_LU_KEY** und **YOUR_LU_ENDPOINT** ein.\r\n",
        "\r\n",
        "4. Führen Sie die folgende Zelle aus, indem Sie links neben der Zelle auf die Schaltfläche **Zelle ausführen** (&#9655;) klicken. Geben Sie den Text *licht einschalten* ein, wenn Sie dazu aufgefordert werden. Der Text wird von Ihrem Language Understanding-Modell interpretiert, und ein entsprechendes Bild wird angezeigt.\r\n",
        "\r\n",
        "### **(!) Wichtig**: \r\n",
        "Achten Sie auf die Eingabeaufforderung am oberen Fensterrand. Geben Sie *licht einschalten* ein, und drücken Sie die **Eingabetaste**. \r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from python_code import luis\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    # Set up API configuration\n",
        "    luis_app_id = 'YOUR_LU_APP_ID'\n",
        "    luis_key = 'YOUR_LU_KEY'\n",
        "    luis_endpoint = 'YOUR_LU_ENDPOINT'\n",
        "\n",
        "    # prompt for a command\n",
        "    command = input('Please enter a command: \\n')\n",
        "\n",
        "    # get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, command)\n",
        "\n",
        "    # display an appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696381331
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (!) Überprüfung \r\n",
        "Haben Sie die Zelle oben ausgeführt und anschließend den Ausdruck *licht einschalten* eingegeben, als Sie dazu aufgefordert wurden? Die Eingabeaufforderung wird ganz oben im Fenster angezeigt.  \r\n",
        "\r\n",
        "Führen Sie die Zelle oben erneut mit den folgenden Ausdrücken aus:\r\n",
        "\r\n",
        "* *licht einschalten*\r\n",
        "* *lampe abschalten*\r\n",
        "* *ventilator anschalten*\r\n",
        "* *licht anschalten*\r\n",
        "* *licht abschalten*\r\n",
        "* *ventilator ausschalten*\r\n",
        "* *lüftung anschalten*\r\n",
        "\r\n",
        "Wenn beim Ausführen der Zelle oben ein Fragezeichen angezeigt wurde, bedeutet dies, dass Ihr eingegebener Text nicht exakt mit dem übereinstimmt, was Sie beim Erstellen von Entität, Absicht oder Äußerung eingegeben haben.\r\n",
        "\r\n",
        "> **Hinweis**: Falls Sie sich für den Code interessieren, mit dem die Absichten und Entitäten aus Ihrer Language Understanding-App abgerufen werden, können Sie sich die Datei **luis.py** im Ordner **python_code** ansehen."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hinzufügen von Sprachbefehlen\r\n",
        "\r\n",
        "Bisher haben Sie gelernt, Text zu analysieren. Wir können jedoch auch in zunehmendem Maße per Spracherkennung mit Softwarediensten kommunizieren. Für diese Kommunikation stellt der Cognitive Service **Speech** eine einfache Methode zum Transkribieren von gesprochener Sprache zu Text bereit.\r\n",
        "\r\n",
        "### Erstellen einer Cognitive Services-Ressource\r\n",
        "\r\n",
        "Falls noch nicht geschehen, führen Sie die folgenden Schritte aus, um eine **Cognitive Services**-Ressource in Ihrem Azure-Abonnement zu erstellen:\r\n",
        "\r\n",
        "> **Hinweis**: Falls Sie bereits eine Cognitive Services-Ressource haben, können Sie die entsprechende **Schnellstart**-Seite im Azure-Portal öffnen und den Schlüssel und Speicherort der Ressource unten in die Zelle kopieren. Führen Sie andernfalls die folgenden Schritte aus, um eine Ressource zu erstellen.\r\n",
        "\r\n",
        "1. Öffnen Sie das Azure-Portal unter [https://portal.azure.com](https://portal.azure.com) in einer neuen Browserregisterkarte, und melden Sie sich mit Ihrem Microsoft-Konto an.\r\n",
        "2. Klicken Sie auf die Schaltfläche **&#65291;Ressource erstellen**, suchen Sie nach *Cognitive Services*, und erstellen Sie eine **Cognitive Services**-Ressource mit den folgenden Einstellungen:\r\n",
        "    - **Abonnement**: *Ihr Azure-Abonnement*\r\n",
        "    - **Ressourcengruppe**: *Wählen Sie eine Ressourcengruppe aus, oder erstellen Sie eine Ressourcengruppe mit einem eindeutigen Namen.*\r\n",
        "    - **Region**: *Wählen Sie eine verfügbare Region aus*:\r\n",
        "    - **Name**: *Geben Sie einen eindeutigen Namen ein.*\r\n",
        "    - **Tarif**: S0\r\n",
        "    - **Durch das Ankreuzen dieses Felds versichere ich, dass dieser Dienst nicht für eine Polizeiabteilung in den USA eingesetzt wird**: Ausgewählt\r\n",
        "    - **Ich bestätige, dass ich die Hinweise gelesen und verstanden habe**: Ausgewählt\r\n",
        "3. Warten Sie, bis die Bereitstellung abgeschlossen ist. Öffnen Sie anschließend Ihre Cognitive Services-Ressource, und notieren Sie sich die Schlüssel und den Speicherort auf der Seite **Schnellstart**. Sie benötigen diese Werte, um sich aus Clientanwendungen heraus mit Ihrer Cognitive Services-Ressource zu verbinden.\r\n",
        "\r\n",
        "### Abrufen des Schlüssels und des Speicherorts für Ihre Cognitive Services-Ressource\r\n",
        "\r\n",
        "Um Ihre Cognitive Services-Ressource verwenden zu können, benötigen Clientanwendungen deren Authentifizierungsschlüssel und Speicherort:\r\n",
        "\r\n",
        "1. Kopieren Sie im Azure-Portal auf der Seite **Schlüssel und Endpunkt** für Ihre Cognitive Service-Ressource den **Schlüssel1** für Ihre Ressource, und fügen Sie ihn im unten stehenden Code anstelle von **YOUR_COG_KEY** ein.\r\n",
        "2. Kopieren Sie den **Speicherort** für Ihre Ressource, und fügen Sie ihn unten im Code anstelle von **YOUR_COG_LOCATION** ein.\r\n",
        ">**Hinweis**: Bleiben Sie auf der Seite **Schlüssel und Endpunkt**, und kopieren Sie den **Speicherort** von dieser Seite (Beispiel: _westus_). Fügen Sie KEINE Leerzeichen zwischen den Wörtern im Feld „Speicherort“ ein. \r\n",
        "3. Führen Sie den Code in der folgenden Zelle aus. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696409914
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Führen Sie jetzt die folgende Zelle aus, um gesprochenen Text aus einer Audiodatei zu transkribieren und als Befehl für Ihre Language Understanding-App zu verwenden."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from python_code import luis\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "from playsound import playsound\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "try:   \n",
        "\n",
        "    # Get spoken command from audio file\n",
        "    file_name = 'light-on.wav'\n",
        "    audio_file = os.path.join('data', 'luis', file_name)\n",
        "\n",
        "    # Configure speech recognizer\n",
        "    speech_config = SpeechConfig(cog_key, cog_location)\n",
        "    audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "    # Use a one-time, synchronous call to transcribe the speech\n",
        "    speech = speech_recognizer.recognize_once()\n",
        "\n",
        "    # Get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, speech.text)\n",
        "\n",
        "    # Get the appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "\n",
        "    # Display image \n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "    playsound(audio_file)\n",
        "\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696420498
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passen Sie die obige Zelle so an, dass sie die Audiodatei **light-off.wav** verwendet.\r\n",
        "\r\n",
        "## Weitere Informationen\r\n",
        "\r\n",
        "Weitere Informationen zum Language Understanding-Dienst finden Sie in der [Dokumentation für den Dienst](https://docs.microsoft.com/azure/cognitive-services/luis/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}